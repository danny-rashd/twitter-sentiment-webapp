{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfee631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb0383",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"news-sentiment.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea0d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_positive = []\n",
    "list_negative = []\n",
    "list_neutral = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964a8454",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    if(row['label'] == \"Positive\"):\n",
    "        list_positive.append(row['text'])\n",
    "    elif(row['label'] == \"Negative\"):\n",
    "        list_negative.append(row['text'])\n",
    "    elif(row['label'] == 'Neutral'):\n",
    "        list_neutral.append(row['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd084d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bert_pol = pd.read_csv(r\"sv_twitter_politics.csv\",sep=\"\\t\")\n",
    "data_bert_pol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41184b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTxt(text):\n",
    "  text= re.sub(r'@[A-Za-z0-9]+','',text) #Remove @mentions\n",
    "  text= re.sub(r'#','',text) #Remove # symbols\n",
    "  text= re.sub(r'RT[\\s]+','',text) #Removing RT\n",
    "  text= re.sub(r'https?:\\/\\/\\S+','',text) #Remove hyperlink\n",
    "  return text\n",
    "\n",
    "#Cleaning the text\n",
    "data_bert_pol['text']=data_bert_pol['text'].apply(cleanTxt)\n",
    "\n",
    "#Show the cleaned text\n",
    "data_bert_pol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c112bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data_bert_pol.iterrows():\n",
    "    if(row['sentiment'] == \"Positive\"):\n",
    "        list_positive.append(row['text'])\n",
    "    elif(row['sentiment'] == \"Negative\"):\n",
    "        list_negative.append(row['text'])\n",
    "    elif(row['sentiment'] == 'Neutral'):\n",
    "        list_neutral.append(row['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7580d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_twt = pd.read_csv(r\"sv_twitter.csv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_twt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eefd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTxt(text):\n",
    "  text= re.sub(r'@[A-Za-z0-9]+','',text) #Remove @mentions\n",
    "  text= re.sub(r'#','',text) #Remove # symbols\n",
    "  text= re.sub(r'RT[\\s]+','',text) #Removing RT\n",
    "  text= re.sub(r'https?:\\/\\/\\S+','',text) #Remove hyperlink\n",
    "  return text\n",
    "\n",
    "#Cleaning the text\n",
    "data_twt['text']=data_twt['text'].apply(cleanTxt)\n",
    "\n",
    "#Show the cleaned text\n",
    "data_twt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5297ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data_twt.iterrows():\n",
    "    if(row['sentiment'] == \"Positive\"):\n",
    "        list_positive.append(row['text'])\n",
    "    elif(row['sentiment'] == \"Negative\"):\n",
    "        list_negative.append(row['text'])\n",
    "    elif(row['sentiment'] == 'Neutral'):\n",
    "        list_neutral.append(row['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bfc39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Neutral: {len(list_neutral)}\")\n",
    "print(f\"Positive: {len(list_positive)}\")\n",
    "print(f\"Negative: {len(list_negative)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752db37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_negative = pd.read_json(r\"json\\neg\\strong_negatives.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96fa865",
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_negative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b083bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in strong_negative.iterrows():\n",
    "    list_negative.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cf3c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_positive = pd.read_json(r\"json\\pos\\strong-positives.json\")\n",
    "strong_positive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456f9e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in strong_positive.iterrows():\n",
    "    list_positive.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deddfd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Neutral: {len(list_neutral)}\")\n",
    "print(f\"Positive: {len(list_positive)}\")\n",
    "print(f\"Negative: {len(list_negative)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eec3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_lst = []\n",
    "for pos in list_positive:\n",
    "    pos_lst.append(pos.replace(\"\\n\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5bb50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_lst = []\n",
    "for neut in list_neutral:\n",
    "    neutral_lst.append(neut.replace(\"\\n\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a17d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_lst = []\n",
    "for neg in list_negative:\n",
    "    neg_lst.append(neg.replace(\"\\n\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32332b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(pos_lst)\n",
    "random.shuffle(neg_lst)\n",
    "random.shuffle(neutral_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d794bbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = pos_lst[:10000]\n",
    "train_neg = neg_lst[:10000]\n",
    "train_neutral = neutral_lst[:10000]\n",
    "\n",
    "test_pos = pos_lst[-10000:]\n",
    "test_neg = neg_lst[-10000:]\n",
    "test_neutral = neutral_lst[-10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5d420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_train = pd.DataFrame(train_pos)\n",
    "neg_train = pd.DataFrame(train_neg)\n",
    "neutral_train = pd.DataFrame(train_neutral)\n",
    "\n",
    "pos_test = pd.DataFrame(test_pos)\n",
    "neg_test = pd.DataFrame(test_neg)\n",
    "neutral_test = pd.DataFrame(test_neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e814a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train files\n",
    "pos_train.to_csv(r\"C:\\Users\\User\\OneDrive\\Desktop\\Skymind\\Python\\sentiment_split\\positive.txt\", header=None, index=None, sep='\\n', mode='w')\n",
    "neg_train.to_csv(r\"C:\\Users\\User\\OneDrive\\Desktop\\Skymind\\Python\\sentiment_split\\negative.txt\", header=None, index=None, sep='\\n', mode='w')\n",
    "neutral_train.to_csv(r\"C:\\Users\\User\\OneDrive\\Desktop\\Skymind\\Python\\sentiment_split\\neutral.txt\", header=None, index=None, sep='\\n', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44f7b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test files\n",
    "pos_test.to_csv(r\"C:\\Users\\User\\OneDrive\\Desktop\\Skymind\\Python\\sentiment_split\\pos_test.txt\", header=None, index=None, sep='\\n', mode='w')\n",
    "neg_test.to_csv(r\"C:\\Users\\User\\OneDrive\\Desktop\\Skymind\\Python\\sentiment_split\\neg_test.txt\", header=None, index=None, sep='\\n', mode='w')\n",
    "neutral_test.to_csv(r\"C:\\Users\\User\\OneDrive\\Desktop\\Skymind\\Python\\sentiment_split\\neutral_test.txt\", header=None, index=None, sep='\\n', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edef4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pos_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fdd964",
   "metadata": {},
   "outputs": [],
   "source": [
    "string=open('positive.txt').read()\n",
    "new_str = re.sub(r'@[A-Za-z0-9]+','',string) #Remove @mentions\n",
    "open('pos_1.txt', 'w').write(new_str)\n",
    "\n",
    "string1= open('pos_1.txt').read()\n",
    "new_str2= re.sub(r'#','',string1) #Remove # symbols\n",
    "open('pos_2.txt', 'w').write(new_str2)\n",
    "\n",
    "string2= open('pos_2.txt').read()\n",
    "new_str3= re.sub(r'RT[\\s]+','',string2) #Removing RT\n",
    "open('pos_3.txt', 'w').write(new_str3)\n",
    "\n",
    "string3= open('pos_3.txt').read()\n",
    "new_str4= re.sub(r'https?:\\/\\/\\S+','',string3) #Remove hyperlink\n",
    "open('pos_4.txt', 'w').write(new_str4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a19720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "string=open('negative.txt').read()\n",
    "new_str = re.sub(r'@[A-Za-z0-9]+','',string) #Remove @mentions\n",
    "open('neg_1.txt', 'w').write(new_str)\n",
    "\n",
    "string1= open('neg_1.txt').read()\n",
    "new_str2= re.sub(r'#','',string1) #Remove # symbols\n",
    "open('neg_2.txt', 'w').write(new_str2)\n",
    "\n",
    "string2= open('neg_2.txt').read()\n",
    "new_str3= re.sub(r'RT[\\s]+','',string2) #Removing RT\n",
    "open('neg_3.txt', 'w').write(new_str3)\n",
    "\n",
    "string3= open('neg_3.txt').read()\n",
    "new_str4= re.sub(r'https?:\\/\\/\\S+','',string3) #Remove hyperlink\n",
    "open('neg_final.txt', 'w').write(new_str4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ccafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "string=open('malay_dump.txt').read()\n",
    "new_str = re.sub(r'@[A-Za-z0-9]+','',string) #Remove @mentions\n",
    "open('pos_1.txt', 'w').write(new_str)\n",
    "\n",
    "string=open('malay_dump.txt').read()\n",
    "new_str = re.sub(r'#[A-Za-z0-9]+','',string) #Remove @hastags\n",
    "open('pos_1.txt', 'w').write(new_str)\n",
    "\n",
    "string1= open('pos_1.txt').read()\n",
    "new_str2= re.sub(r'#','',string1) #Remove # symbols\n",
    "open('pos_2.txt', 'w').write(new_str2)\n",
    "\n",
    "string2= open('pos_2.txt').read()\n",
    "new_str3= re.sub(r'RT[\\s]+','',string2) #Removing RT\n",
    "open('pos_3.txt', 'w').write(new_str3)\n",
    "\n",
    "string3= open('pos_3.txt').read()\n",
    "new_str4= re.sub(r'https?:\\/\\/\\S+','',string3) #Remove hyperlink\n",
    "open('malay_dump_cleaned.txt', 'w').write(new_str4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada7ca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two files\n",
    "data = data2 = \"\"\n",
    "  \n",
    "# Reading data from file1\n",
    "with open('filtered-dumping-wiki.txt') as fp:\n",
    "    data = fp.read()\n",
    "  \n",
    "# Reading data from file2\n",
    "with open('dumping-instagram.txt') as fp:\n",
    "    data2 = fp.read()\n",
    "  \n",
    "# Merging 2 files to create new files\n",
    "data += \"\\n\"\n",
    "data += data2\n",
    "with open ('malay_dump.txt', 'w') as fp:\n",
    "    fp.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa8532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove lines from the txt file\n",
    "with open('malay_dump3.txt', 'r') as f:\n",
    "    c = f.read()\n",
    "\n",
    "with open('malay_dump4_noline.txt', 'wb') as f:\n",
    "    f.write(bytes(''.join(c).replace('\\n', ''),  'utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98668beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove non-alphanumeric char from txt\n",
    "import re\n",
    "string = open('malay_dump_cleaned.txt').read()\n",
    "str = re.sub('[^a-zA-Z.\\n]', ' ', string)\n",
    "open('malay_dump_cleaned_nonum.txt', 'w').write(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea3f04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split big text file into smaller ones\n",
    "lines_per_file = 150000\n",
    "smallfile = None\n",
    "with open('malay_dump_cleaned1000000.txt') as bigfile:\n",
    "    for lineno, line in enumerate(bigfile):\n",
    "        if lineno % lines_per_file == 0:\n",
    "            if smallfile:\n",
    "                smallfile.close()\n",
    "            small_filename = 'malay_dump_cleaned_{}.txt'.format(lineno + lines_per_file)\n",
    "            smallfile = open(small_filename, \"w\")\n",
    "        smallfile.write(line)\n",
    "    if smallfile:\n",
    "        smallfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ec7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random shuffle lines in file\n",
    "import random\n",
    "with open('malay_cleaned_file_rand2.txt','r') as source:\n",
    "    data = [ (random.random(), line) for line in source ]\n",
    "data.sort()\n",
    "with open('malay_cleaned_file_rand3.txt','w') as target:\n",
    "    for _, line in data:\n",
    "        target.write( line )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c426f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stopwords from file\n",
    "infile = \"malay_cleaned.txt\"\n",
    "outfile = \"malay_cleaned_final.txt\"\n",
    "\n",
    "delete_list = [\"bisa\"]\n",
    "\n",
    "with open(infile) as fin, open(outfile, \"w+\") as fout:\n",
    "    for line in fin:\n",
    "        for word in delete_list:\n",
    "            line = line.replace(word, \"\")\n",
    "        fout.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
